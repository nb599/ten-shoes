# 将 AI 能力引入前端：从数据流到体验的完整落地指南

> 这是一篇面向工程实践的文章，讨论如何稳妥地把大模型能力接入 Web 前端，覆盖数据流、UI 模式、函数调用、缓存与可观测性。所有示例以 Next.js App Router 为参考。

## 1. 能力边界与系统切分

- 前端擅长：交互编排、流式展示、状态管理、可视化与可回放。
- 服务端擅长：鉴权、配额、审计、敏感信息存储、模型聚合与重试。
- 经验法则：**前端不直连模型**，通过服务端 Proxy（如 AI Gateway 或自建 Router）进行调用与观测，降低泄露与绕桶风险。

## 2. 数据流与 UI：流式一等公民

为什么要流式？
- 降低感知延迟，提升完成前反馈。
- 支持**可中断**与**思维展开**（Chain-of-Thought 可控显隐）。
- 支持 token 级“打字机”效果、差量 patch、逐步可用。

前端注意：
- 对齐“中止”与“清理”语义。AbortController 统一取消。
- 针对移动端弱网，逐段渲染 + 错误块内聚（每段可重试）。

## 3. 函数调用 vs. 工具调用

- 统一函数签名（JSON Schema）并在前端做**静态可视化**（参数面板、示例）。
- 函数调用的可回放：把“自然语言意图 + 工具调用参数 + 结果”持久化，作为诊断与 A/B 的基线。

前端落地要点：
- 工具调用日志卡片化（Timeline）。
- 失败重放：保留最近一次参数快照，支持单步 Retry。

## 4. RSC 与边缘：让数据离用户更近

- 使用 Server Components 进行首屏拼装，减少水合负担。
- 把“模型调用”放到**边缘**（Edge/Region）以降低时延，但要评估配额和冷启动。
- 对静态段落（如“提示词建议”、“常见 Q&A”）使用 ISR 或静态导出。

## 5. 体验范式

- Draft-then-commit：先给粗略答案，随后“补丁式完善”。
- Intent Folding：把用户的冗长输入折叠成“核心意图卡片”。
- 懒加载的知识：引用证据块（Sources）按需展开，避免噪音。

## 6. 可靠性与可观测性

- 记录每次会话的 traceId，串联前端与后端日志。
- 关键指标：延迟分布、失败率、工具调用成功率、平均轮数、内容长度。
- 前端埋点：渲染段耗时、取消率、重试率、滚动阅读深度。

## 7. 缓存策略

- Prompt 片段与少量静态资源可本地缓存（IndexedDB）。
- 对结果页面启用 ISR；对用户私有数据不缓存。
- 语义搜索结果需要**命中版本**，避免仓库变更引起语义漂移。

## 8. 风险与合规

- 前端不存储密钥，使用服务器端路由转发并加上速率限制。
- 对敏感输入做本地提示（如“包含隐私信息”）并提供匿名化建议。
- 给出“模型局限”声明，提供反馈渠道。

## 9. 小结

将 AI 能力引入前端的关键，不是“能不能调用”，而是**体验、可回放与可靠性**。把“流式、可中断、可重试、可观测”当作一等公民，才能让应用在真实环境中跑得稳、成长得快。
